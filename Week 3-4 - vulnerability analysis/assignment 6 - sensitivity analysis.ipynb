{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "# Week 3 - Sensitivity analysis\n",
    "\n",
    "This exercise uses the same predator-prey model we used for the multi-model exercise, focusing on the Python version. As with the other exercise, define a model object for the function below, with the uncertainty ranges provided:\n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "\n",
    "* Sensitivity analysis often focuses on the final values of an outcome at the end of the simulation. However, we can also look at metrics that give us additional information about the behavior of the model over time. Using [the statsmodel library](https://www.statsmodels.org/stable/index.html) and an appropriate sampling design, fit a linear regression model for each of the following indicators. What can we conclude about the behavior of the model, and about the importance of the different inputs?\n",
    "\n",
    "  * The final values of the _prey_ outcome\n",
    "  * The mean values of the _prey_ outcome over time, within each experiment\n",
    "  * The standard deviations of the _prey_ outcome over time, within each experiment\n",
    "  \n",
    "\n",
    "* Use the Sobol sampling functionality included in the Workbench to perform experiments with a sample size of N=50, then analyze the results with SALib for the same three indicators. This requires specifying the keyword argument `'uncertainty_sampling'` of perform_experiments. Note that when using Sobol sampling, the meaning of the keyword argument `scenarios` changes a bit. In order to properly estimate Sobol scores as well as interaction effects, you require N * (2D+2) scenarios, where D is the number of uncertain parameters, and N is the value for scenarios passed to `perform_experiments`. Repeat the analysis for larger sample sizes, with N=250 and N=1000. How can we interpret the first-order and total indices? Are these sample sizes sufficient for a stable estimation of the indices? You'll need to use the [get_SALib_problem](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/em_framework/salib_samplers.html) function to convert your Workbench experiments to a problem definition that you can pass to the SALib analysis function. \n",
    "\n",
    "* *hint*: sobol is a deterministic sequence of quasi random numbers. Thus, you can run with N=1000 and simply slice for 1:50 and 1:250.\n",
    "\n",
    "* Use the [Extra-Trees analysis](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/feature_scoring.html) included in the Workbench to approximate the Sobol total indices, with a suitable sampling design. As a starting point, use an ensemble of 100 trees and a max_features parameter of 0.6, and set the analysis to regression mode. Are the estimated importances stable relative to the sample size and the analysis parameters? How do the results compare to the Sobol indices? For more details on this analysis see [Jaxa-Rozen & Kwakkel (2018)](https://www.sciencedirect.com/science/article/pii/S1364815217311581)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging, MultiprocessingEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS\n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "from predprey_function import pred_prey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] pool started\n[MainProcess/INFO] performing 100 scenarios * 1 policies * 1 model(s) = 100 experiments\n[MainProcess/INFO] 10 cases completed\n[MainProcess/INFO] 20 cases completed\n[MainProcess/INFO] 30 cases completed\n[MainProcess/INFO] 40 cases completed\n[MainProcess/INFO] 50 cases completed\n[MainProcess/INFO] 60 cases completed\n[MainProcess/INFO] 70 cases completed\n[MainProcess/INFO] 80 cases completed\n[MainProcess/INFO] 90 cases completed\n[MainProcess/INFO] 100 cases completed\n[MainProcess/INFO] experiments finished\n[MainProcess/INFO] terminating pool\n"
    }
   ],
   "source": [
    "#Initiate Model\n",
    "model = Model(name=\"PredPreyModel\", function = pred_prey)\n",
    "\n",
    "#Define Uncertainties\n",
    "model.uncertainties = [RealParameter('prey_birth_rate', 0.015 , 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005 , 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001 , 0.004),\n",
    "                       RealParameter('predator_loss_rate', 0.04 , 0.08)]\n",
    "\n",
    "#Define Outcomes\n",
    "model.outcomes = [TimeSeriesOutcome('TIME'),\n",
    "                  TimeSeriesOutcome('predators'),\n",
    "                  TimeSeriesOutcome('prey')]\n",
    "\n",
    "#Turn on logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "n_scenarios = 100\n",
    "\n",
    "with MultiprocessingEvaluator(model, n_processes=7) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(n_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    predation_rate  predator_efficiency  predator_loss_rate  prey_birth_rate  \\\n0         0.000623             0.001284            0.059635         0.023242   \n1         0.000866             0.001308            0.054265         0.017208   \n2         0.001787             0.002117            0.068028         0.027821   \n3         0.002663             0.001398            0.074432         0.018794   \n4         0.002938             0.002280            0.065890         0.029334   \n..             ...                  ...                 ...              ...   \n95        0.002982             0.002621            0.075168         0.021845   \n96        0.000694             0.001029            0.072167         0.034068   \n97        0.000828             0.001331            0.041692         0.016687   \n98        0.001528             0.002018            0.064131         0.030295   \n99        0.001314             0.001856            0.043788         0.024285   \n\n   scenario policy          model  \n0         0   None  PredPreyModel  \n1         1   None  PredPreyModel  \n2         2   None  PredPreyModel  \n3         3   None  PredPreyModel  \n4         4   None  PredPreyModel  \n..      ...    ...            ...  \n95       95   None  PredPreyModel  \n96       96   None  PredPreyModel  \n97       97   None  PredPreyModel  \n98       98   None  PredPreyModel  \n99       99   None  PredPreyModel  \n\n[100 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predation_rate</th>\n      <th>predator_efficiency</th>\n      <th>predator_loss_rate</th>\n      <th>prey_birth_rate</th>\n      <th>scenario</th>\n      <th>policy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000623</td>\n      <td>0.001284</td>\n      <td>0.059635</td>\n      <td>0.023242</td>\n      <td>0</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000866</td>\n      <td>0.001308</td>\n      <td>0.054265</td>\n      <td>0.017208</td>\n      <td>1</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.001787</td>\n      <td>0.002117</td>\n      <td>0.068028</td>\n      <td>0.027821</td>\n      <td>2</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002663</td>\n      <td>0.001398</td>\n      <td>0.074432</td>\n      <td>0.018794</td>\n      <td>3</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002938</td>\n      <td>0.002280</td>\n      <td>0.065890</td>\n      <td>0.029334</td>\n      <td>4</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.002982</td>\n      <td>0.002621</td>\n      <td>0.075168</td>\n      <td>0.021845</td>\n      <td>95</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.000694</td>\n      <td>0.001029</td>\n      <td>0.072167</td>\n      <td>0.034068</td>\n      <td>96</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.000828</td>\n      <td>0.001331</td>\n      <td>0.041692</td>\n      <td>0.016687</td>\n      <td>97</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.001528</td>\n      <td>0.002018</td>\n      <td>0.064131</td>\n      <td>0.030295</td>\n      <td>98</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.001314</td>\n      <td>0.001856</td>\n      <td>0.043788</td>\n      <td>0.024285</td>\n      <td>99</td>\n      <td>None</td>\n      <td>PredPreyModel</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#create the right dataframe\n",
    "prey = outcomes['prey']\n",
    "\n",
    "#results = smf.ols('Lottery ~ Literacy + np.log(Pop1831)', data=dat).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}