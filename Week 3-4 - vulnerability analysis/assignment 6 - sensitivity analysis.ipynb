{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "# Week 3 - Sensitivity analysis\n",
    "\n",
    "This exercise uses the same predator-prey model we used for the multi-model exercise, focusing on the Python version. As with the other exercise, define a model object for the function below, with the uncertainty ranges provided:\n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "\n",
    "* Sensitivity analysis often focuses on the final values of an outcome at the end of the simulation. However, we can also look at metrics that give us additional information about the behavior of the model over time. Using [the statsmodel library](https://www.statsmodels.org/stable/index.html) and an appropriate sampling design, fit a linear regression model for each of the following indicators. What can we conclude about the behavior of the model, and about the importance of the different inputs?\n",
    "\n",
    "  * The final values of the _prey_ outcome\n",
    "  * The mean values of the _prey_ outcome over time, within each experiment\n",
    "  * The standard deviations of the _prey_ outcome over time, within each experiment\n",
    "  \n",
    "\n",
    "* Use the Sobol sampling functionality included in the Workbench to perform experiments with a sample size of N=50, then analyze the results with SALib for the same three indicators. This requires specifying the keyword argument `'uncertainty_sampling'` of perform_experiments. Note that when using Sobol sampling, the meaning of the keyword argument `scenarios` changes a bit. In order to properly estimate Sobol scores as well as interaction effects, you require N * (2D+2) scenarios, where D is the number of uncertain parameters, and N is the value for scenarios passed to `perform_experiments`. Repeat the analysis for larger sample sizes, with N=250 and N=1000. How can we interpret the first-order and total indices? Are these sample sizes sufficient for a stable estimation of the indices? You'll need to use the [get_SALib_problem](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/em_framework/salib_samplers.html) function to convert your Workbench experiments to a problem definition that you can pass to the SALib analysis function. \n",
    "\n",
    "* *hint*: sobol is a deterministic sequence of quasi random numbers. Thus, you can run with N=1000 and simply slice for 1:50 and 1:250.\n",
    "\n",
    "* Use the [Extra-Trees analysis](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/feature_scoring.html) included in the Workbench to approximate the Sobol total indices, with a suitable sampling design. As a starting point, use an ensemble of 100 trees and a max_features parameter of 0.6, and set the analysis to regression mode. Are the estimated importances stable relative to the sample size and the analysis parameters? How do the results compare to the Sobol indices? For more details on this analysis see [Jaxa-Rozen & Kwakkel (2018)](https://www.sciencedirect.com/science/article/pii/S1364815217311581)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:22: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  'ipyparallel not installed - IpyparalleEvaluator not available')\n",
      "C:\\Users\\Ashok\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:48: ImportWarning: platypus based optimization not available\n",
      "  warnings.warn(\"platypus based optimization not available\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging, MultiprocessingEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS\n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "from predprey_function import pred_prey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 100 scenarios * 1 policies * 1 model(s) = 100 experiments\n",
      "[MainProcess/INFO] 10 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 30 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] 50 cases completed\n",
      "[MainProcess/INFO] 60 cases completed\n",
      "[MainProcess/INFO] 70 cases completed\n",
      "[MainProcess/INFO] 80 cases completed\n",
      "[MainProcess/INFO] 90 cases completed\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "#Initiate Model\n",
    "model = Model(name=\"PredPreyModel\", function = pred_prey)\n",
    "\n",
    "#Define Uncertainties\n",
    "model.uncertainties = [RealParameter('prey_birth_rate', 0.015 , 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005 , 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001 , 0.004),\n",
    "                       RealParameter('predator_loss_rate', 0.04 , 0.08)]\n",
    "\n",
    "#Define Outcomes\n",
    "model.outcomes = [TimeSeriesOutcome('TIME'),\n",
    "                  TimeSeriesOutcome('predators'),\n",
    "                  TimeSeriesOutcome('prey')]\n",
    "\n",
    "#Turn on logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "n_scenarios = 100\n",
    "\n",
    "with MultiprocessingEvaluator(model, n_processes=7) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(n_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predation_rate</th>\n",
       "      <th>predator_efficiency</th>\n",
       "      <th>predator_loss_rate</th>\n",
       "      <th>prey_birth_rate</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.060539</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.022405</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.077572</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.021367</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.070171</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.062524</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.040914</td>\n",
       "      <td>0.024642</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.060989</td>\n",
       "      <td>0.032089</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.078785</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.044362</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.077840</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.055357</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.049032</td>\n",
       "      <td>0.019482</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.072938</td>\n",
       "      <td>0.034753</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.076845</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.060344</td>\n",
       "      <td>0.030911</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.053402</td>\n",
       "      <td>0.015824</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.074213</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.067207</td>\n",
       "      <td>0.023788</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.051224</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.049842</td>\n",
       "      <td>0.028706</td>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>28</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.051982</td>\n",
       "      <td>0.034873</td>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>71</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.021417</td>\n",
       "      <td>72</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.043174</td>\n",
       "      <td>0.020751</td>\n",
       "      <td>73</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.064956</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>74</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.055750</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.059776</td>\n",
       "      <td>0.020068</td>\n",
       "      <td>76</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>77</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.072402</td>\n",
       "      <td>0.030622</td>\n",
       "      <td>78</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.044410</td>\n",
       "      <td>0.031118</td>\n",
       "      <td>79</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.049339</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.058318</td>\n",
       "      <td>0.025885</td>\n",
       "      <td>81</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.067067</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>82</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.063623</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>83</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>84</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>85</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>0.029829</td>\n",
       "      <td>86</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.079993</td>\n",
       "      <td>0.027184</td>\n",
       "      <td>87</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>0.027852</td>\n",
       "      <td>88</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.061327</td>\n",
       "      <td>0.016832</td>\n",
       "      <td>89</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.063172</td>\n",
       "      <td>0.029347</td>\n",
       "      <td>90</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.052665</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>91</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.079267</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>92</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>93</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>94</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>95</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.076102</td>\n",
       "      <td>0.028181</td>\n",
       "      <td>96</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.028248</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.058635</td>\n",
       "      <td>0.034455</td>\n",
       "      <td>98</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>0.027409</td>\n",
       "      <td>99</td>\n",
       "      <td>None</td>\n",
       "      <td>PredPreyModel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predation_rate  predator_efficiency  predator_loss_rate  prey_birth_rate  \\\n",
       "0         0.000540             0.001721            0.060539         0.025085   \n",
       "1         0.001839             0.003663            0.072066         0.022405   \n",
       "2         0.001824             0.001647            0.077572         0.027338   \n",
       "3         0.001362             0.001530            0.046779         0.021367   \n",
       "4         0.002634             0.002918            0.070171         0.017638   \n",
       "5         0.001297             0.002223            0.062524         0.026560   \n",
       "6         0.002996             0.003633            0.040914         0.024642   \n",
       "7         0.002323             0.002580            0.060989         0.032089   \n",
       "8         0.001502             0.003795            0.078785         0.032413   \n",
       "9         0.000946             0.002450            0.069608         0.022019   \n",
       "10        0.002381             0.002856            0.044362         0.022317   \n",
       "11        0.002188             0.001002            0.064109         0.017086   \n",
       "12        0.001908             0.002546            0.077840         0.032242   \n",
       "13        0.001334             0.001578            0.042252         0.025397   \n",
       "14        0.002824             0.002724            0.055357         0.026875   \n",
       "15        0.000884             0.001036            0.049032         0.019482   \n",
       "16        0.001928             0.001497            0.072938         0.034753   \n",
       "17        0.001677             0.003831            0.076845         0.029059   \n",
       "18        0.002024             0.003402            0.059036         0.028413   \n",
       "19        0.002235             0.003925            0.060344         0.030911   \n",
       "20        0.002651             0.002304            0.056995         0.017900   \n",
       "21        0.002516             0.001477            0.053402         0.015824   \n",
       "22        0.002203             0.001859            0.074213         0.018077   \n",
       "23        0.000570             0.001814            0.052949         0.018246   \n",
       "24        0.001406             0.001876            0.045051         0.018827   \n",
       "25        0.001091             0.001440            0.067207         0.023788   \n",
       "26        0.001032             0.002256            0.051224         0.033919   \n",
       "27        0.000973             0.002513            0.049842         0.028706   \n",
       "28        0.001159             0.003571            0.050700         0.026700   \n",
       "29        0.002893             0.001236            0.051982         0.034873   \n",
       "..             ...                  ...                 ...              ...   \n",
       "70        0.002124             0.003695            0.063394         0.029632   \n",
       "71        0.001789             0.001977            0.062167         0.024864   \n",
       "72        0.001065             0.001187            0.054356         0.021417   \n",
       "73        0.002705             0.001995            0.043174         0.020751   \n",
       "74        0.002148             0.003243            0.064956         0.021691   \n",
       "75        0.000789             0.002485            0.055750         0.030215   \n",
       "76        0.000609             0.001318            0.059776         0.020068   \n",
       "77        0.001598             0.001335            0.066498         0.030142   \n",
       "78        0.002738             0.001416            0.072402         0.030622   \n",
       "79        0.000813             0.002813            0.044410         0.031118   \n",
       "80        0.002907             0.003476            0.049339         0.031429   \n",
       "81        0.000677             0.002372            0.058318         0.025885   \n",
       "82        0.000754             0.003987            0.067067         0.025735   \n",
       "83        0.002266             0.003712            0.063623         0.024105   \n",
       "84        0.002455             0.003527            0.079019         0.019324   \n",
       "85        0.001245             0.003101            0.065359         0.023199   \n",
       "86        0.001969             0.003850            0.048415         0.029829   \n",
       "87        0.000728             0.001361            0.079993         0.027184   \n",
       "88        0.002350             0.002146            0.043263         0.027852   \n",
       "89        0.000654             0.002118            0.061327         0.016832   \n",
       "90        0.002777             0.003157            0.063172         0.029347   \n",
       "91        0.002970             0.003365            0.052665         0.022605   \n",
       "92        0.001867             0.002967            0.079267         0.034208   \n",
       "93        0.001900             0.001097            0.074688         0.016523   \n",
       "94        0.001385             0.002407            0.041777         0.031986   \n",
       "95        0.002837             0.001176            0.069360         0.020916   \n",
       "96        0.000718             0.003386            0.076102         0.028181   \n",
       "97        0.001021             0.003003            0.052200         0.028248   \n",
       "98        0.002031             0.001782            0.058635         0.034455   \n",
       "99        0.001601             0.003053            0.059265         0.027409   \n",
       "\n",
       "   scenario policy          model  \n",
       "0         0   None  PredPreyModel  \n",
       "1         1   None  PredPreyModel  \n",
       "2         2   None  PredPreyModel  \n",
       "3         3   None  PredPreyModel  \n",
       "4         4   None  PredPreyModel  \n",
       "5         5   None  PredPreyModel  \n",
       "6         6   None  PredPreyModel  \n",
       "7         7   None  PredPreyModel  \n",
       "8         8   None  PredPreyModel  \n",
       "9         9   None  PredPreyModel  \n",
       "10       10   None  PredPreyModel  \n",
       "11       11   None  PredPreyModel  \n",
       "12       12   None  PredPreyModel  \n",
       "13       13   None  PredPreyModel  \n",
       "14       14   None  PredPreyModel  \n",
       "15       15   None  PredPreyModel  \n",
       "16       16   None  PredPreyModel  \n",
       "17       17   None  PredPreyModel  \n",
       "18       18   None  PredPreyModel  \n",
       "19       19   None  PredPreyModel  \n",
       "20       20   None  PredPreyModel  \n",
       "21       21   None  PredPreyModel  \n",
       "22       22   None  PredPreyModel  \n",
       "23       23   None  PredPreyModel  \n",
       "24       24   None  PredPreyModel  \n",
       "25       25   None  PredPreyModel  \n",
       "26       26   None  PredPreyModel  \n",
       "27       27   None  PredPreyModel  \n",
       "28       28   None  PredPreyModel  \n",
       "29       29   None  PredPreyModel  \n",
       "..      ...    ...            ...  \n",
       "70       70   None  PredPreyModel  \n",
       "71       71   None  PredPreyModel  \n",
       "72       72   None  PredPreyModel  \n",
       "73       73   None  PredPreyModel  \n",
       "74       74   None  PredPreyModel  \n",
       "75       75   None  PredPreyModel  \n",
       "76       76   None  PredPreyModel  \n",
       "77       77   None  PredPreyModel  \n",
       "78       78   None  PredPreyModel  \n",
       "79       79   None  PredPreyModel  \n",
       "80       80   None  PredPreyModel  \n",
       "81       81   None  PredPreyModel  \n",
       "82       82   None  PredPreyModel  \n",
       "83       83   None  PredPreyModel  \n",
       "84       84   None  PredPreyModel  \n",
       "85       85   None  PredPreyModel  \n",
       "86       86   None  PredPreyModel  \n",
       "87       87   None  PredPreyModel  \n",
       "88       88   None  PredPreyModel  \n",
       "89       89   None  PredPreyModel  \n",
       "90       90   None  PredPreyModel  \n",
       "91       91   None  PredPreyModel  \n",
       "92       92   None  PredPreyModel  \n",
       "93       93   None  PredPreyModel  \n",
       "94       94   None  PredPreyModel  \n",
       "95       95   None  PredPreyModel  \n",
       "96       96   None  PredPreyModel  \n",
       "97       97   None  PredPreyModel  \n",
       "98       98   None  PredPreyModel  \n",
       "99       99   None  PredPreyModel  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "experiments_clean = experiments.drop(columns=['scenario','policy','model'])\n",
    "\n",
    "experiments_clean.values.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[50.        , 50.1786847 , 50.35714383, ..., 63.13043764,\n",
       "         63.12329785, 63.11130879]],\n",
       "\n",
       "       [[50.        , 49.82033004, 49.62858277, ..., 36.90028147,\n",
       "         37.0901315 , 37.28069125]],\n",
       "\n",
       "       [[50.        , 49.8857647 , 49.77124506, ..., 51.98111778,\n",
       "         52.07964544, 52.17784165]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[50.        , 50.09779551, 50.18951776, ..., 23.05911182,\n",
       "         23.20993923, 23.36170164]],\n",
       "\n",
       "       [[50.        , 49.92301665, 49.84229111, ..., 21.83196435,\n",
       "         21.90364976, 21.97614642]],\n",
       "\n",
       "       [[50.        , 49.94233958, 49.87540906, ..., 51.61028648,\n",
       "         51.74439569, 51.87344276]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the right dataframe\n",
    "prey = outcomes['prey']\n",
    "prey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   538.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 May 2020</td> <th>  Prob (F-statistic):</th>          <td>8.17e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:47:26</td>     <th>  Log-Likelihood:    </th>          <td> -324.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>   657.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th>          <td>   667.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>  968.6672</td> <td>  852.670</td> <td>    1.136</td> <td> 0.259</td> <td> -723.870</td> <td> 2661.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>-1.208e+04</td> <td>  750.443</td> <td>  -16.093</td> <td> 0.000</td> <td>-1.36e+04</td> <td>-1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>  753.8808</td> <td>   39.009</td> <td>   19.326</td> <td> 0.000</td> <td>  676.448</td> <td>  831.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>  382.0868</td> <td>   96.818</td> <td>    3.946</td> <td> 0.000</td> <td>  189.905</td> <td>  574.269</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.496</td> <th>  Durbin-Watson:     </th> <td>   2.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.064</td> <th>  Jarque-Bera (JB):  </th> <td>   4.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.515</td> <th>  Prob(JB):          </th> <td>  0.0866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.336</td> <th>  Cond. No.          </th> <td>    93.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.957\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.956\n",
       "Method:                 Least Squares   F-statistic:                              538.6\n",
       "Date:                Fri, 15 May 2020   Prob (F-statistic):                    8.17e-65\n",
       "Time:                        11:47:26   Log-Likelihood:                         -324.71\n",
       "No. Observations:                 100   AIC:                                      657.4\n",
       "Df Residuals:                      96   BIC:                                      667.8\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1           968.6672    852.670      1.136      0.259    -723.870    2661.204\n",
       "x2         -1.208e+04    750.443    -16.093      0.000   -1.36e+04   -1.06e+04\n",
       "x3           753.8808     39.009     19.326      0.000     676.448     831.313\n",
       "x4           382.0868     96.818      3.946      0.000     189.905     574.269\n",
       "==============================================================================\n",
       "Omnibus:                        5.496   Durbin-Watson:                   2.489\n",
       "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.892\n",
       "Skew:                           0.515   Prob(JB):                       0.0866\n",
       "Kurtosis:                       3.336   Cond. No.                         93.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_mean = np.mean(outcomes['prey'][:,0,:], axis=1)\n",
    "prey_mean\n",
    "\n",
    "LR_mean = statsmodels.regression.linear_model.OLS(prey_mean, experiments_clean.values)\n",
    "\n",
    "fitted_mean = LR_mean.fit()\n",
    "\n",
    "fitted_mean.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   106.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 May 2020</td> <th>  Prob (F-statistic):</th>          <td>1.83e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:47:26</td>     <th>  Log-Likelihood:    </th>          <td> -418.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>   845.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th>          <td>   856.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>-2867.0535</td> <td> 2186.353</td> <td>   -1.311</td> <td> 0.193</td> <td>-7206.931</td> <td> 1472.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>-1.107e+04</td> <td> 1924.230</td> <td>   -5.756</td> <td> 0.000</td> <td>-1.49e+04</td> <td>-7255.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>  917.2398</td> <td>  100.025</td> <td>    9.170</td> <td> 0.000</td> <td>  718.693</td> <td> 1115.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>  321.6891</td> <td>  248.253</td> <td>    1.296</td> <td> 0.198</td> <td> -171.090</td> <td>  814.468</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.620</td> <th>  Durbin-Watson:     </th> <td>   1.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  26.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.787</td> <th>  Prob(JB):          </th> <td>1.42e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.996</td> <th>  Cond. No.          </th> <td>    93.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.816\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.809\n",
       "Method:                 Least Squares   F-statistic:                              106.8\n",
       "Date:                Fri, 15 May 2020   Prob (F-statistic):                    1.83e-34\n",
       "Time:                        11:47:26   Log-Likelihood:                         -418.87\n",
       "No. Observations:                 100   AIC:                                      845.7\n",
       "Df Residuals:                      96   BIC:                                      856.2\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1         -2867.0535   2186.353     -1.311      0.193   -7206.931    1472.824\n",
       "x2         -1.107e+04   1924.230     -5.756      0.000   -1.49e+04   -7255.405\n",
       "x3           917.2398    100.025      9.170      0.000     718.693    1115.787\n",
       "x4           321.6891    248.253      1.296      0.198    -171.090     814.468\n",
       "==============================================================================\n",
       "Omnibus:                       17.620   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.926\n",
       "Skew:                           0.787   Prob(JB):                     1.42e-06\n",
       "Kurtosis:                       4.996   Cond. No.                         93.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_final = outcomes['prey'][:,:,-1].flatten()\n",
    "prey_final\n",
    "\n",
    "LR_final = statsmodels.regression.linear_model.OLS(prey_final, experiments_clean.values)\n",
    "\n",
    "fitted_final = LR_final.fit()\n",
    "\n",
    "\n",
    "fitted_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   279.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 May 2020</td> <th>  Prob (F-statistic):</th>          <td>5.70e-52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:47:26</td>     <th>  Log-Likelihood:    </th>          <td> -285.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>   579.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th>          <td>   590.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td> 2481.3073</td> <td>  578.724</td> <td>    4.288</td> <td> 0.000</td> <td> 1332.550</td> <td> 3630.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td> 1431.7708</td> <td>  509.340</td> <td>    2.811</td> <td> 0.006</td> <td>  420.739</td> <td> 2442.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   86.8272</td> <td>   26.476</td> <td>    3.279</td> <td> 0.001</td> <td>   34.272</td> <td>  139.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   42.0862</td> <td>   65.712</td> <td>    0.640</td> <td> 0.523</td> <td>  -88.351</td> <td>  172.524</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.843</td> <th>  Durbin-Watson:     </th> <td>   1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>  21.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.340</td> <th>  Prob(JB):          </th> <td>2.26e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.162</td> <th>  Cond. No.          </th> <td>    93.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.921\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.918\n",
       "Method:                 Least Squares   F-statistic:                              279.6\n",
       "Date:                Fri, 15 May 2020   Prob (F-statistic):                    5.70e-52\n",
       "Time:                        11:47:26   Log-Likelihood:                         -285.96\n",
       "No. Observations:                 100   AIC:                                      579.9\n",
       "Df Residuals:                      96   BIC:                                      590.3\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1          2481.3073    578.724      4.288      0.000    1332.550    3630.065\n",
       "x2          1431.7708    509.340      2.811      0.006     420.739    2442.803\n",
       "x3            86.8272     26.476      3.279      0.001      34.272     139.382\n",
       "x4            42.0862     65.712      0.640      0.523     -88.351     172.524\n",
       "==============================================================================\n",
       "Omnibus:                       10.843   Durbin-Watson:                   1.973\n",
       "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               21.395\n",
       "Skew:                           0.340   Prob(JB):                     2.26e-05\n",
       "Kurtosis:                       5.162   Cond. No.                         93.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_std = np.std(outcomes['prey'][:,0,:], axis=1)\n",
    "prey_std\n",
    "\n",
    "LR_std = statsmodels.regression.linear_model.OLS(prey_std, experiments_clean.values)\n",
    "\n",
    "fitted_std = LR_std.fit()\n",
    "\n",
    "\n",
    "fitted_std.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOBOL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 5000 scenarios * 1 policies * 1 model(s) = 5000 experiments\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1500 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] 2500 cases completed\n",
      "[MainProcess/INFO] 3000 cases completed\n",
      "[MainProcess/INFO] 3500 cases completed\n",
      "[MainProcess/INFO] 4000 cases completed\n",
      "[MainProcess/INFO] 4500 cases completed\n",
      "[MainProcess/INFO] 5000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    sa_results = evaluator.perform_experiments(scenarios=500,\n",
    "                                               uncertainty_sampling='sobol')\n",
    "\n",
    "experiments, outcomes = sa_results\n",
    "\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "\n",
    "\n",
    "#Si = sobol.analyze(problem, outcomes['predation_rate'],\n",
    "                  # calc_second_order=True, print_to_console=False)\n",
    "#Si = sobol.analyze(problem, outcomes['predator_efficiency'],\n",
    "                 #  calc_second_order=True, print_to_console=False)\n",
    "#Si = sobol.analyze(problem, outcomes['predator_loss_rate'],\n",
    "                 #  calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1, 1461)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes[\"prey\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_mean = np.mean(outcomes['prey'][:,0,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48.40509047, 47.87568608, 14.66124704, ..., 10.03022204,\n",
       "       10.08351765, 10.36774874])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si = sobol.analyze(problem, prey_mean,\n",
    "                   calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_filtered = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "indices = Si_df[['S1','ST']]\n",
    "err = Si_df[['S1_conf','ST_conf']]\n",
    "\n",
    "indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "fig.set_size_inches(8,6)\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predation_rate</th>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.005425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predator_efficiency</th>\n",
       "      <td>0.773630</td>\n",
       "      <td>0.828010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predator_loss_rate</th>\n",
       "      <td>0.184630</td>\n",
       "      <td>0.215999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prey_birth_rate</th>\n",
       "      <td>0.010348</td>\n",
       "      <td>0.010643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           S1        ST\n",
       "predation_rate       0.000661  0.005425\n",
       "predator_efficiency  0.773630  0.828010\n",
       "predator_loss_rate   0.184630  0.215999\n",
       "prey_birth_rate      0.010348  0.010643"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.analyze.sobol import analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_results= {}\n",
    "for policy in experiments.policy.unique():\n",
    "    logical = experiments.policy == policy\n",
    "    y= prey_mean[logical]\n",
    "    indices=analyze(problem, y)\n",
    "    sobol_results[policy] = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'None': {'S1': array([6.60614808e-04, 7.73630208e-01, 1.84630497e-01, 1.03480193e-02]),\n",
       "  'S1_conf': array([0.00842284, 0.10694416, 0.05631373, 0.01402997]),\n",
       "  'ST': array([0.00542464, 0.82801021, 0.21599854, 0.01064252]),\n",
       "  'ST_conf': array([0.00152763, 0.08905813, 0.03273321, 0.00193797]),\n",
       "  'S2': array([[        nan, -0.00097873,  0.00285568, -0.00141365],\n",
       "         [        nan,         nan,  0.03886788, -0.00615334],\n",
       "         [        nan,         nan,         nan, -0.01406847],\n",
       "         [        nan,         nan,         nan,         nan]]),\n",
       "  'S2_conf': array([[       nan, 0.01721283, 0.01215387, 0.0121104 ],\n",
       "         [       nan,        nan, 0.18546093, 0.15713987],\n",
       "         [       nan,        nan,        nan, 0.09874139],\n",
       "         [       nan,        nan,        nan,        nan]])}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobol_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y={'prey': prey_mean}\n",
    "#y_ST={\"ST\": indices['ST']}\n",
    "#     'max. infected fraction': np.max(outcomes['infected fraction R1'], axis=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] policy dropped from analysis because only a single category\n",
      "[MainProcess/INFO] model dropped from analysis because only a single category\n"
     ]
    }
   ],
   "source": [
    "scores=feature_scoring.get_feature_scores_all(x=experiments, y=y , mode=feature_scoring.RuleInductionType.REGRESSION, max_features=0.6, nr_trees=100, alg=\"extra trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(scores, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
